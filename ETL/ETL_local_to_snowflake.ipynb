{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating login request with your identity provider. A browser window should have opened for you to complete the login. If you can't see it, check existing browser windows, or your OS settings. Press CTRL+C to abort and try again...\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "import re\n",
    "import snowflake.connector\n",
    "# from snowflake.sqlalchemy import URL\n",
    "# from sqlalchemy import create_engine\n",
    "from snowflake.connector import ProgrammingError\n",
    "\n",
    "# Gets the credentials\n",
    "with open('/Users/cyndiz/Documents/Projects/credentials/snowflake.json') as f:\n",
    "    config2 = json.load(f)     \n",
    "\n",
    "# Connect to DB\n",
    "con = snowflake.connector.connect(\n",
    "    user=config2['username'],\n",
    "    password=config2['password'],\n",
    "    account=config2['account'],\n",
    "    authenticator='externalbrowser',\n",
    "    warehouse='WH_MARKETING_SCIENCE_XXL',\n",
    "    database='MARKETING_SCIENCE',\n",
    "    schema='LOCAL'\n",
    "    )\n",
    "\n",
    "cur = con.cursor()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/cyndiz/Documents/Projects/PI001-MetaMMM/ElsyMMM/Farmers/2022-06-30 11.51 init/model_stats.csv',\n",
       " '/Users/cyndiz/Documents/Projects/PI001-MetaMMM/ElsyMMM/Farmers/2022-06-30 11.51 init/Weekly_long.csv',\n",
       " '/Users/cyndiz/Documents/Projects/PI001-MetaMMM/ElsyMMM/Farmers/2022-06-30 11.51 init/ScenarioPlanning.csv',\n",
       " '/Users/cyndiz/Documents/Projects/PI001-MetaMMM/ElsyMMM/Farmers/2022-06-30 11.51 init/pareto_alldecomp_matrix.csv']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from snowflake.connector.pandas_tools import write_pandas\n",
    "\n",
    "foldername = '/Users/cyndiz/Documents/Projects/PI001-MetaMMM/ElsyMMM/Farmers/2022-06-30 11.51 init/'\n",
    "\n",
    "filenames = [\n",
    "    foldername+'model_stats.csv',\n",
    "    foldername+'Weekly_long.csv',\n",
    "    foldername+'ScenarioPlanning.csv',\n",
    "    foldername+'pareto_alldecomp_matrix.csv'\n",
    "]\n",
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/cyndiz/Documents/Projects/PI001-MetaMMM/ElsyMMM/Farmers/2022-06-30 11.51 init/ScenarioPlanning.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/cyndiz/Documents/Projects/Repo/automation/ETL/ETL_local_to_snowflake.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/cyndiz/Documents/Projects/Repo/automation/ETL/ETL_local_to_snowflake.ipynb#ch0000004?line=1'>2</a>\u001b[0m schema\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mCZHONG\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/cyndiz/Documents/Projects/Repo/automation/ETL/ETL_local_to_snowflake.ipynb#ch0000004?line=2'>3</a>\u001b[0m client\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mDEMO\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/cyndiz/Documents/Projects/Repo/automation/ETL/ETL_local_to_snowflake.ipynb#ch0000004?line=3'>4</a>\u001b[0m df_sp \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(foldername\u001b[39m+\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mScenarioPlanning.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/cyndiz/Documents/Projects/Repo/automation/ETL/ETL_local_to_snowflake.ipynb#ch0000004?line=4'>5</a>\u001b[0m sol_id \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(df_sp[\u001b[39m'\u001b[39m\u001b[39msolID\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39munique())\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/cyndiz/Documents/Projects/Repo/automation/ETL/ETL_local_to_snowflake.ipynb#ch0000004?line=5'>6</a>\u001b[0m start_ds \u001b[39m=\u001b[39m df_sp[\u001b[39m'\u001b[39m\u001b[39mds\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mmin()\n",
      "File \u001b[0;32m~/Documents/Projects/PI001-MetaMMM/ElsyMMM/mmm/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/Projects/PI001-MetaMMM/ElsyMMM/mmm/lib/python3.9/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/Documents/Projects/PI001-MetaMMM/ElsyMMM/mmm/lib/python3.9/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    577\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/Documents/Projects/PI001-MetaMMM/ElsyMMM/mmm/lib/python3.9/site-packages/pandas/io/parsers/readers.py:934\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    933\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 934\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/Documents/Projects/PI001-MetaMMM/ElsyMMM/mmm/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1218\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1214\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1215\u001b[0m \u001b[39m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m \u001b[39m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1217\u001b[0m \u001b[39m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1218\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(  \u001b[39m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1219\u001b[0m     f,\n\u001b[1;32m   1220\u001b[0m     mode,\n\u001b[1;32m   1221\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1222\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1223\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1224\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1225\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1226\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1227\u001b[0m )\n\u001b[1;32m   1228\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1229\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/Documents/Projects/PI001-MetaMMM/ElsyMMM/mmm/lib/python3.9/site-packages/pandas/io/common.py:786\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    782\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    785\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 786\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    787\u001b[0m             handle,\n\u001b[1;32m    788\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    789\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    790\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    791\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    792\u001b[0m         )\n\u001b[1;32m    793\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    794\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    795\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/cyndiz/Documents/Projects/PI001-MetaMMM/ElsyMMM/Farmers/2022-06-30 11.51 init/ScenarioPlanning.csv'"
     ]
    }
   ],
   "source": [
    "database='MARKETING_SCIENCE'\n",
    "schema='CZHONG'\n",
    "client='DEMO'\n",
    "df_sp = pd.read_csv(foldername+'ScenarioPlanning.csv')\n",
    "sol_id = list(df_sp['solID'].unique())\n",
    "start_ds = df_sp['ds'].min()\n",
    "end_ds = df_sp['ds'].max()\n",
    "date_range = 'From %s to %s with covid only'%(start_ds,end_ds)\n",
    "\n",
    "cur.execute('''create or replace file format myformat type='CSV' skip_header=1;''')\n",
    "cur.execute('''create or replace stage stage_mmm file_format=myformat copy_options = (on_error='skip_file');''')\n",
    "for filename in filenames:\n",
    "    print(filename)\n",
    "    # qry_put= '''PUT file://{filename} @stage_mmm;'''.format(filename=filename)\n",
    "    filename_model = pd.read_csv(filename)\n",
    "    filename_model.replace([np.inf, -np.inf],0, inplace=True)\n",
    "    filename_model['client']=client\n",
    "    filename_model.columns = map(str.upper, filename_model.columns)\n",
    "    if re.search('model_stats.csv',filename):\n",
    "        # tablename = 'MARKETING_SCIENCE.CZHONG.MMM_MODEL_STATS'\n",
    "        tablename='MMM_MODEL_STATS'\n",
    "        filename_model=filename_model.rename(columns={'DECOMP.RSSD':'DECOMP_RSSD'})\n",
    "        # print(filename_model.loc[filename_model['SOLID']=='5_238_6'])\n",
    "        filename_model['DATE_RANGE']=date_range\n",
    "        names = filename_model.columns\n",
    "        formatted_names = list(map(lambda x: ('{x} varchar' if (x in ('SOLID','RN','CLIENT','DATE_RANGE')) else '{x} float').format(x=x), names))\n",
    "    elif re.search('Weekly_long.csv', filename):\n",
    "        # tablename = 'MARKETING_SCIENCE.CZHONG.MMM_RAW'\n",
    "        tablename = 'MMM_RAW'\n",
    "        filename_model=filename_model.rename(columns={'BM.SALES_CALLS.PRD.54':'SALES_CALLS'})\n",
    "        # filename_model['DATE']=pd.to_datetime(filename_model['DATE'])\n",
    "        names = filename_model.columns\n",
    "        formatted_names = list(map(lambda x: ('{x} varchar' if (x in ('METRICS','CLIENT')) else ('{x} date' if x=='DATE' else '{x} float')).format(x=x), names))\n",
    "    elif re.search('ScenarioPlanning.csv',filename):\n",
    "        # tablename = 'MARKETING_SCIENCE.CZHONG.MMM_SCENARIO_PLANNING'\n",
    "        tablename = 'MMM_SCENARIO_PLANNING'\n",
    "        # filename_model['DS']=pd.to_datetime(filename_model['DS'])\n",
    "        filename_model['DATE_RANGE']=date_range\n",
    "        names = filename_model.columns\n",
    "        formatted_names = list(map(lambda x: ('{x} varchar' if (x in ('CHANNEL','SOLID','CLIENT','TYPE','DATE_RANGE')) else ('{x} date' if x=='DS' else ('{x} boolean' if x=='FLAG_MEAN' else '{x} float'))).format(x=x), names))\n",
    "    elif re.search('pareto_alldecomp_matrix.csv',filename):\n",
    "        tablename = 'MMM_RESPONSE'\n",
    "        filename_model = filename_model.loc[filename_model['SOLID'].isin(sol_id)]\n",
    "        filename_model = filename_model[['DS','DEP_VAR','DEPVARHAT','CLIENT','SOLID']]\n",
    "        filename_model['DATE_RANGE']=date_range\n",
    "        names = filename_model.columns\n",
    "        formatted_names = list(map(lambda x: ('{x} varchar' if (x in ('CHANNEL','SOLID','CLIENT','TYPE','DATE_RANGE')) else ('{x} date' if x=='DS' else ('{x} boolean' if x=='FLAG_MEAN' else '{x} float'))).format(x=x), names))\n",
    "    col_n = ',\\n'.join(formatted_names)\n",
    "    print(col_n)\n",
    "    qry_create = '''CREATE TABLE IF NOT EXISTS {database}.{schema}.{tablename} ({col_n}) CLUSTER BY (CLIENT); '''.format(col_n=col_n,tablename=tablename,database=database,schema=schema)\n",
    "    # qry_create = '''CREATE OR REPLACE TABLE {database}.{schema}.{tablename} ({col_n}) CLUSTER BY (CLIENT); '''.format(col_n=col_n,tablename=tablename,database=database,schema=schema)\n",
    "    if tablename in ('MMM_RESPONSE','MMM_SCENARIO_PLANNING','MMM_MODEL_STATS'):\n",
    "        qry_delete = '''DELETE FROM {database}.{schema}.{tablename} WHERE client='{client}' and date_range='{date_range}';'''.format(tablename=tablename,database=database,schema=schema,date_range=date_range,client=client)\n",
    "    else:\n",
    "        qry_delete = '''DELETE FROM {database}.{schema}.{tablename} WHERE client='{client}';'''.format(tablename=tablename,database=database,schema=schema,client=client)\n",
    "    # qry_copy = '''COPY INTO {tablename} from @stage_mmm;'''.format(tablename=tablename)\n",
    "    # cur.execute(qry_put)\n",
    "    cur.execute(qry_create)\n",
    "    # print('Table created!')\n",
    "    cur.execute(qry_delete)\n",
    "    # cur.execute(qry_copy)\n",
    "    success, nchunks, nrows, _ = write_pandas(con, filename_model, '{tablename}'.format(tablename=tablename),database='MARKETING_SCIENCE',schema='CZHONG')\n",
    "    cur.execute('''select * from {tablename} limit 10;'''.format(tablename=database+'.'+schema+'.'+tablename))\n",
    "    rows=cur.fetch_pandas_all()\n",
    "    print(rows)\n",
    "print('Upload Successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DS</th>\n",
       "      <th>DEP_VAR</th>\n",
       "      <th>DEPVARHAT</th>\n",
       "      <th>CLIENT</th>\n",
       "      <th>SOLID</th>\n",
       "      <th>DATE_RANGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-26</td>\n",
       "      <td>86019.0</td>\n",
       "      <td>84142.960924</td>\n",
       "      <td>Farmer</td>\n",
       "      <td>1_222_8</td>\n",
       "      <td>From 2018-12-30 to 2022-05-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-03-10</td>\n",
       "      <td>93981.0</td>\n",
       "      <td>104633.156599</td>\n",
       "      <td>Farmer</td>\n",
       "      <td>1_222_8</td>\n",
       "      <td>From 2018-12-30 to 2022-05-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-04-07</td>\n",
       "      <td>85773.0</td>\n",
       "      <td>95542.161305</td>\n",
       "      <td>Farmer</td>\n",
       "      <td>1_222_8</td>\n",
       "      <td>From 2018-12-30 to 2022-05-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-06-02</td>\n",
       "      <td>90005.0</td>\n",
       "      <td>82330.035845</td>\n",
       "      <td>Farmer</td>\n",
       "      <td>1_222_8</td>\n",
       "      <td>From 2018-12-30 to 2022-05-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-09-01</td>\n",
       "      <td>79936.0</td>\n",
       "      <td>75183.817938</td>\n",
       "      <td>Farmer</td>\n",
       "      <td>1_222_8</td>\n",
       "      <td>From 2018-12-30 to 2022-05-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38838</th>\n",
       "      <td>2022-02-21</td>\n",
       "      <td>2193.0</td>\n",
       "      <td>2809.758698</td>\n",
       "      <td>Farmer</td>\n",
       "      <td>5_92_7</td>\n",
       "      <td>From 2018-12-31 to 2022-05-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38839</th>\n",
       "      <td>2022-04-25</td>\n",
       "      <td>2905.0</td>\n",
       "      <td>2835.133773</td>\n",
       "      <td>Farmer</td>\n",
       "      <td>5_92_7</td>\n",
       "      <td>From 2018-12-31 to 2022-05-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38840</th>\n",
       "      <td>2022-05-16</td>\n",
       "      <td>3209.0</td>\n",
       "      <td>2932.251806</td>\n",
       "      <td>Farmer</td>\n",
       "      <td>5_92_7</td>\n",
       "      <td>From 2018-12-31 to 2022-05-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38841</th>\n",
       "      <td>2021-09-27</td>\n",
       "      <td>3038.0</td>\n",
       "      <td>2509.181594</td>\n",
       "      <td>Farmer</td>\n",
       "      <td>5_92_7</td>\n",
       "      <td>From 2018-12-31 to 2022-05-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38842</th>\n",
       "      <td>2020-10-05</td>\n",
       "      <td>2660.0</td>\n",
       "      <td>2873.636732</td>\n",
       "      <td>Farmer</td>\n",
       "      <td>5_92_7</td>\n",
       "      <td>From 2018-12-31 to 2022-05-30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38843 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               DS  DEP_VAR      DEPVARHAT  CLIENT    SOLID  \\\n",
       "0      2020-01-26  86019.0   84142.960924  Farmer  1_222_8   \n",
       "1      2019-03-10  93981.0  104633.156599  Farmer  1_222_8   \n",
       "2      2019-04-07  85773.0   95542.161305  Farmer  1_222_8   \n",
       "3      2019-06-02  90005.0   82330.035845  Farmer  1_222_8   \n",
       "4      2019-09-01  79936.0   75183.817938  Farmer  1_222_8   \n",
       "...           ...      ...            ...     ...      ...   \n",
       "38838  2022-02-21   2193.0    2809.758698  Farmer   5_92_7   \n",
       "38839  2022-04-25   2905.0    2835.133773  Farmer   5_92_7   \n",
       "38840  2022-05-16   3209.0    2932.251806  Farmer   5_92_7   \n",
       "38841  2021-09-27   3038.0    2509.181594  Farmer   5_92_7   \n",
       "38842  2020-10-05   2660.0    2873.636732  Farmer   5_92_7   \n",
       "\n",
       "                          DATE_RANGE  \n",
       "0      From 2018-12-30 to 2022-05-29  \n",
       "1      From 2018-12-30 to 2022-05-29  \n",
       "2      From 2018-12-30 to 2022-05-29  \n",
       "3      From 2018-12-30 to 2022-05-29  \n",
       "4      From 2018-12-30 to 2022-05-29  \n",
       "...                              ...  \n",
       "38838  From 2018-12-31 to 2022-05-30  \n",
       "38839  From 2018-12-31 to 2022-05-30  \n",
       "38840  From 2018-12-31 to 2022-05-30  \n",
       "38841  From 2018-12-31 to 2022-05-30  \n",
       "38842  From 2018-12-31 to 2022-05-30  \n",
       "\n",
       "[38843 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cur.execute('select * from marketing_science.czhong.mmm_response;')\n",
    "rows=cur.fetch_pandas_all()\n",
    "display(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'****From 2018-12-31 to 2022-05-30'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23628"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filename_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DS</th>\n",
       "      <th>DEP_VAR</th>\n",
       "      <th>DEPVARHAT</th>\n",
       "      <th>CLIENT</th>\n",
       "      <th>SOLID</th>\n",
       "      <th>DATE_RANGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1611</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>3371</td>\n",
       "      <td>3941.507189</td>\n",
       "      <td>Farmer</td>\n",
       "      <td>2_171_2</td>\n",
       "      <td>From 2018-12-31 to 2022-05-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1612</th>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>4281</td>\n",
       "      <td>4403.513312</td>\n",
       "      <td>Farmer</td>\n",
       "      <td>2_171_2</td>\n",
       "      <td>From 2018-12-31 to 2022-05-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1613</th>\n",
       "      <td>2019-01-14</td>\n",
       "      <td>4382</td>\n",
       "      <td>4469.551877</td>\n",
       "      <td>Farmer</td>\n",
       "      <td>2_171_2</td>\n",
       "      <td>From 2018-12-31 to 2022-05-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1614</th>\n",
       "      <td>2019-01-21</td>\n",
       "      <td>4280</td>\n",
       "      <td>4065.005199</td>\n",
       "      <td>Farmer</td>\n",
       "      <td>2_171_2</td>\n",
       "      <td>From 2018-12-31 to 2022-05-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1615</th>\n",
       "      <td>2019-01-28</td>\n",
       "      <td>4604</td>\n",
       "      <td>4376.337891</td>\n",
       "      <td>Farmer</td>\n",
       "      <td>2_171_2</td>\n",
       "      <td>From 2018-12-31 to 2022-05-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18969</th>\n",
       "      <td>2022-05-02</td>\n",
       "      <td>3113</td>\n",
       "      <td>2827.571824</td>\n",
       "      <td>Farmer</td>\n",
       "      <td>3_217_2</td>\n",
       "      <td>From 2018-12-31 to 2022-05-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18970</th>\n",
       "      <td>2022-05-09</td>\n",
       "      <td>3049</td>\n",
       "      <td>2866.271853</td>\n",
       "      <td>Farmer</td>\n",
       "      <td>3_217_2</td>\n",
       "      <td>From 2018-12-31 to 2022-05-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18971</th>\n",
       "      <td>2022-05-16</td>\n",
       "      <td>3209</td>\n",
       "      <td>2924.412086</td>\n",
       "      <td>Farmer</td>\n",
       "      <td>3_217_2</td>\n",
       "      <td>From 2018-12-31 to 2022-05-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18972</th>\n",
       "      <td>2022-05-23</td>\n",
       "      <td>3277</td>\n",
       "      <td>2895.634100</td>\n",
       "      <td>Farmer</td>\n",
       "      <td>3_217_2</td>\n",
       "      <td>From 2018-12-31 to 2022-05-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18973</th>\n",
       "      <td>2022-05-30</td>\n",
       "      <td>3034</td>\n",
       "      <td>2643.312875</td>\n",
       "      <td>Farmer</td>\n",
       "      <td>3_217_2</td>\n",
       "      <td>From 2018-12-31 to 2022-05-30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>895 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               DS  DEP_VAR    DEPVARHAT  CLIENT    SOLID  \\\n",
       "1611   2018-12-31     3371  3941.507189  Farmer  2_171_2   \n",
       "1612   2019-01-07     4281  4403.513312  Farmer  2_171_2   \n",
       "1613   2019-01-14     4382  4469.551877  Farmer  2_171_2   \n",
       "1614   2019-01-21     4280  4065.005199  Farmer  2_171_2   \n",
       "1615   2019-01-28     4604  4376.337891  Farmer  2_171_2   \n",
       "...           ...      ...          ...     ...      ...   \n",
       "18969  2022-05-02     3113  2827.571824  Farmer  3_217_2   \n",
       "18970  2022-05-09     3049  2866.271853  Farmer  3_217_2   \n",
       "18971  2022-05-16     3209  2924.412086  Farmer  3_217_2   \n",
       "18972  2022-05-23     3277  2895.634100  Farmer  3_217_2   \n",
       "18973  2022-05-30     3034  2643.312875  Farmer  3_217_2   \n",
       "\n",
       "                          DATE_RANGE  \n",
       "1611   From 2018-12-31 to 2022-05-30  \n",
       "1612   From 2018-12-31 to 2022-05-30  \n",
       "1613   From 2018-12-31 to 2022-05-30  \n",
       "1614   From 2018-12-31 to 2022-05-30  \n",
       "1615   From 2018-12-31 to 2022-05-30  \n",
       "...                              ...  \n",
       "18969  From 2018-12-31 to 2022-05-30  \n",
       "18970  From 2018-12-31 to 2022-05-30  \n",
       "18971  From 2018-12-31 to 2022-05-30  \n",
       "18972  From 2018-12-31 to 2022-05-30  \n",
       "18973  From 2018-12-31 to 2022-05-30  \n",
       "\n",
       "[895 rows x 6 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol_id = list(df_sp['solID'].unique())\n",
    "a=filename_model.loc[filename_model['SOLID'].isin(sol_id)]\n",
    "len(a)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('mmm': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "67d40bbe546a5a88a29e2efe0d8210338faabf63251442922b130a2ae99d8823"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
